{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ad5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd343511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device.type)\n",
    "\n",
    "# ---\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514d5f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([100, 200, 1]) Y: torch.Size([100, 200, 1])\n"
     ]
    }
   ],
   "source": [
    "t_steps = 200\n",
    "num_demos = 100\n",
    "num_val = 20\n",
    "dx, dy = 1, 1\n",
    "x = torch.linspace(0, 1, t_steps).repeat(int(num_demos/2), 1)\n",
    "\n",
    "noise = torch.clamp(torch.randn(x.shape)*1e-4**0.5, min=0)\n",
    "y0 = torch.unsqueeze(torch.sin(x*torch.pi) + noise, 2)\n",
    "\n",
    "y1 = 1-y0\n",
    "\n",
    "x = torch.unsqueeze(x.repeat(2,1), 2)\n",
    "y = torch.cat((y0, y1), 0)\n",
    "print(\"X:\", x.shape, \"Y:\", y.shape)\n",
    "\n",
    "path = \".\"\n",
    "\n",
    "#######################################\n",
    "\n",
    "vx = torch.linspace(0, 1, t_steps).repeat(int(num_val/2), 1)\n",
    "vnoise = torch.clamp(torch.randn(vx.shape)*1e-4**0.5, min=0)\n",
    "vy0 = torch.unsqueeze(torch.sin(vx*torch.pi) + vnoise, 2)\n",
    "vy1 = 1-vy0\n",
    "\n",
    "vx = torch.unsqueeze(vx.repeat(2,1), 2)\n",
    "vy = torch.cat((vy0, vy1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a2865b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[:50, :, 0], y[:50, :, 0], 'b', alpha=0.3)\n",
    "plt.plot(x[51:, :, 0], y[51:, :, 0], 'r', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b11b723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = 6\n",
    "\n",
    "def sample_training_demonstration():    \n",
    "    rand_traj_ind = np.random.randint(0, num_demos)\n",
    "    n = np.random.randint(1, n_max+1)\n",
    "\n",
    "    rand_traj = y[rand_traj_ind, :, :]\n",
    "\n",
    "    observation_indices = np.random.choice(np.arange(t_steps), n+1, replace=False) # n+1: +1 is for sampling the target\n",
    "    \n",
    "    observations = torch.cat((rand_traj[observation_indices[:-1], :], \n",
    "                              x[rand_traj_ind, observation_indices[:-1], :]), 1)\n",
    "    targetX = torch.unsqueeze(torch.Tensor(x[rand_traj_ind, observation_indices[-1], :]), 0)\n",
    "    targetY = torch.unsqueeze(torch.Tensor(rand_traj[observation_indices[-1], :]), 0)\n",
    "    \n",
    "    type_id = 0 if rand_traj_ind<num_demos/2 else 1\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        return observations.float().cuda(), type_id, targetX.float().cuda(), targetY.float().cuda()\n",
    "    else:\n",
    "        return observations.float(), type_id, targetX.float(), targetY.float()\n",
    "\n",
    "\n",
    "def get_validation_demonstration(ind):\n",
    "    type_id = 0 if ind<num_val/2 else 1\n",
    "    x = vx[ind, :, :]\n",
    "    y = vy[ind, :, :]\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        return x.float().cuda(), y.float().cuda(), type_id\n",
    "    else:\n",
    "        return x, y, type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "334b714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCNP(nn.Module):\n",
    "    def __init__(self, in_shape):\n",
    "        super(BCNP, self).__init__()\n",
    "        \n",
    "        dx, dy = in_shape[0], in_shape[1]\n",
    "        \n",
    "        dz = 128\n",
    "        dzt = dz+dx\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(dx+dy, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dz)\n",
    "        )\n",
    "        \n",
    "        self.f0 = nn.Sequential(\n",
    "            nn.Linear(dzt, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dy*2)\n",
    "        )\n",
    "\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.Linear(dzt, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dy*2)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, observations, type_id, target):\n",
    "        z_out = self.encoder(observations)\n",
    "        z = torch.mean(z_out, dim=0)\n",
    "\n",
    "        zs = z.repeat(target.shape[0], 1).to(device)  # repeating the same z for each target\n",
    "        z_target = torch.cat((zs, target), 1)\n",
    "        \n",
    "        if type_id == 0:\n",
    "            return self.f0(z_target)\n",
    "        else:\n",
    "            return self.f1(z_target)\n",
    "\n",
    "\n",
    "def log_prob_loss(ty, ty_pred):\n",
    "    m, s = ty_pred.chunk(2, dim = -1)\n",
    "    s = F.softplus(s)\n",
    "    dist = D.Independent(D.Normal(loc=m, scale=s), 1)\n",
    "    return -torch.mean(dist.log_prob(ty))\n",
    "\n",
    "\n",
    "def validate():\n",
    "    verr=torch.zeros(num_val)\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_val):\n",
    "            val_x, val_y, type_id = get_validation_demonstration(i)\n",
    "\n",
    "            cond_step = 0\n",
    "            observation = torch.Tensor([val_y[cond_step, :], val_x[cond_step, :]]).view(1, dx+dy).float().cuda()\n",
    "            \n",
    "            pred_traj = torch.zeros_like(val_y)\n",
    "            pred_traj[cond_step, :] = val_y[cond_step, :]\n",
    "\n",
    "            for t in range(1, t_steps):\n",
    "                pred = model(observation, type_id, torch.unsqueeze(val_x[t], 0))\n",
    "                pred_traj[t, :], _ = pred.chunk(2, dim = -1)  # pred[0]: mean, pred[1]: std\n",
    "\n",
    "            verr[i] = torch.sum((val_y - pred_traj) ** 2)\n",
    "    return torch.mean(verr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f19026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112500: 0.020904188975691795\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     model\u001b[38;5;241m.\u001b[39mf1\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 27\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i)\u001b[38;5;241m%\u001b[39mval_after_iter \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     30\u001b[0m     verr \u001b[38;5;241m=\u001b[39m validate()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/_functional.py:103\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    101\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmaximum(max_exp_avg_sqs[i], exp_avg_sq, out\u001b[38;5;241m=\u001b[39mmax_exp_avg_sqs[i])\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Use the max. for normalizing running avg. of gradient\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbias_correction2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BCNP((1, 1))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters(), betas=(0.9, 0.999), amsgrad=True)\n",
    "\n",
    "val_after_iter = 2500\n",
    "iters = 10000000\n",
    "\n",
    "losses = []\n",
    "min_verr = 1e6\n",
    "\n",
    "for i in range(iters):\n",
    "    obss, type_id, tx, ty = sample_training_demonstration()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    ty_preds = model(obss, type_id, tx)\n",
    "    loss = log_prob_loss(ty, ty_preds)\n",
    "    \n",
    "    if type_id == 0:\n",
    "        model.f0.requires_grad = True\n",
    "        model.f1.requires_grad = False\n",
    "    else:\n",
    "        model.f0.requires_grad = False\n",
    "        model.f1.requires_grad = True\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (i)%val_after_iter == 0:\n",
    "        verr = validate()\n",
    "        print(f\"{i}: {verr}\", end=\"\\r\")\n",
    "        losses.append(verr)\n",
    "\n",
    "        if verr < min_verr:\n",
    "            min_verr = verr\n",
    "            torch.save(model.state_dict(), f'{path}/best_model_v0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4371c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(losses[:50])), losses[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64c2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
