{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7ad5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd343511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device.type)\n",
    "\n",
    "# ---\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "514d5f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([100, 200, 1]) Y: torch.Size([100, 200, 1])\n",
      "vX: torch.Size([20, 200, 1]) vY: torch.Size([20, 200, 1])\n"
     ]
    }
   ],
   "source": [
    "def cx_sigm(n=10, t_max=200):\n",
    "    # rand_btw_7-30 * {-1, 1}\n",
    "    c1 = (torch.rand(n, 1) * 23 + 7) #* torch.from_numpy(np.random.choice([-1, 1], (n, 1)))  # c1 for steepness\n",
    "    t = torch.linspace(0, 1, t_max)\n",
    "    c2 = 0.5  # c2 midpoint\n",
    "    \n",
    "    data = 1/(1 + torch.exp(-c1 * (t-c2)))\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_sin(x, amp=1, omega=1, eps=0.1):\n",
    "    r1 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    r2 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    r3 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    return r1*amp*torch.sin(x*omega+r2)+r3\n",
    "\n",
    "\n",
    "def generate_cos(x, amp=1, omega=1, eps=0.1):\n",
    "    r1 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    r2 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    r3 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    return r1*amp*torch.cos(x*omega+r2)+r3\n",
    "\n",
    "\n",
    "def generate_chainsaw(x, amp=1, mod=0.5, eps=0.1):\n",
    "    r1 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    r2 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    r3 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    return r1*amp*((x+r2) % (mod))+r3-amp/4\n",
    "\n",
    "\n",
    "def generate_reverse_chainsaw(x, amp=1, mod=0.5, eps=0.1):\n",
    "    r1 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    r2 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    r3 = torch.rand(1)*(eps*2)+(1-eps)\n",
    "    return -r1*amp*((x+r2) % (mod))+r3+amp/4\n",
    "\n",
    "\n",
    "t_steps = 200\n",
    "num_demos = 100\n",
    "num_val = 20\n",
    "dx, dy = 1, 1\n",
    "x = torch.linspace(0, 1, t_steps).repeat(int(num_demos/2), 1)\n",
    "\n",
    "noise = torch.clamp(torch.randn(x.shape)*1e-4**0.5, min=0) - 0.4\n",
    "y0 = torch.unsqueeze(generate_chainsaw(x) + noise, 2)\n",
    "\n",
    "noise = torch.clamp(torch.randn(x.shape)*1e-4**0.5, min=0) - 0.4\n",
    "# y1 = cx_sigm(int(num_demos/2), t_steps).view(int(num_demos/2), t_steps, 1)\n",
    "# y1 += torch.unsqueeze(noise, 2)\n",
    "\n",
    "y1 = torch.unsqueeze(generate_reverse_chainsaw(x) + noise, 2)\n",
    "\n",
    "x = torch.unsqueeze(x.repeat(2,1), 2)\n",
    "y = torch.cat((y0, y1), 0)\n",
    "print(\"X:\", x.shape, \"Y:\", y.shape)\n",
    "\n",
    "path = \".\"\n",
    "\n",
    "#######################################\n",
    "\n",
    "vx = torch.linspace(0, 1, t_steps).repeat(int(num_val/2), 1)\n",
    "vnoise = torch.clamp(torch.randn(vx.shape)*1e-4**0.5, min=0) - 0.4\n",
    "# vy0 = torch.unsqueeze(torch.sin(vx*torch.pi) + vnoise, 2)\n",
    "vy0 = torch.unsqueeze(generate_chainsaw(vx) + vnoise, 2)\n",
    "\n",
    "vnoise = torch.clamp(torch.randn(vx.shape)*1e-4**0.5, min=0) - 0.4\n",
    "# vy1 = cx_sigm(int(num_val/2), t_steps).view(int(num_val/2), t_steps, 1)\n",
    "# vy1 += torch.unsqueeze(vnoise, 2)\n",
    "vy1 = torch.unsqueeze(generate_reverse_chainsaw(vx) + vnoise, 2)\n",
    "\n",
    "vx = torch.unsqueeze(vx.repeat(2,1), 2)\n",
    "vy = torch.cat((vy0, vy1), 0)\n",
    "print(\"vX:\", vx.shape, \"vY:\", vy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(num_demos/2)):\n",
    "    plt.plot(x[i, :, 0], y[i, :, 0], 'b', alpha=0.3)\n",
    "    plt.plot(x[i+int(num_demos/2), :, 0], y[i+int(num_demos/2), :, 0], 'r', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = 16\n",
    "\n",
    "def sample_training_demonstration():    \n",
    "    rand_traj_ind = np.random.randint(0, num_demos)\n",
    "    n = np.random.randint(1, n_max+1)\n",
    "\n",
    "    rand_traj = y[rand_traj_ind, :, :]\n",
    "\n",
    "    observation_indices = np.random.choice(np.arange(t_steps), n+1, replace=False) # n+1: +1 is for sampling the target\n",
    "    \n",
    "    observations = torch.cat((rand_traj[observation_indices[:-1], :], \n",
    "                              x[rand_traj_ind, observation_indices[:-1], :]), 1)\n",
    "    targetX = torch.unsqueeze(torch.Tensor(x[rand_traj_ind, observation_indices[-1], :]), 0)\n",
    "    targetY = torch.unsqueeze(torch.Tensor(rand_traj[observation_indices[-1], :]), 0)\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        return observations.float().cuda(), targetX.float().cuda(), targetY.float().cuda()\n",
    "    else:\n",
    "        return observations.float(), targetX.float(), targetY.float()\n",
    "\n",
    "\n",
    "def get_validation_demonstration(ind):\n",
    "    x = vx[ind, :, :]\n",
    "    y = vy[ind, :, :]\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        return x.float().cuda(), y.float().cuda()\n",
    "    else:\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCNP(nn.Module):\n",
    "    def __init__(self, in_shape):\n",
    "        super(BCNP, self).__init__()\n",
    "        \n",
    "        dx, dy = in_shape[0], in_shape[1]\n",
    "        \n",
    "        dz = 128\n",
    "        dzt = dz+dx\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(dx+dy, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dz)\n",
    "        )\n",
    "        \n",
    "        self.f0 = nn.Sequential(\n",
    "            nn.Linear(dzt, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dy*2)\n",
    "        )\n",
    "\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.Linear(dzt, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dy*2)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, observations, target):\n",
    "        z_out = self.encoder(observations)\n",
    "        z = torch.mean(z_out, dim=0)\n",
    "\n",
    "        zs = z.repeat(target.shape[0], 1).to(device)  # repeating the same z for each target\n",
    "        z_target = torch.cat((zs, target), 1)\n",
    "        \n",
    "        return self.f0(z_target), self.f1(z_target)\n",
    "\n",
    "\n",
    "def log_prob_loss(ty, ty_pred):\n",
    "    m, s = ty_pred.chunk(2, dim = -1)\n",
    "    s = F.softplus(s)\n",
    "    dist = D.Independent(D.Normal(loc=m, scale=s), 1)\n",
    "    return -torch.mean(dist.log_prob(ty))\n",
    "\n",
    "\n",
    "def plot_trajs(path, i, x, y, pt, col):    \n",
    "    plt.plot(x, y, 'k', alpha=0.5)\n",
    "    plt.plot(x, pt[:, 0], col, alpha=0.75)\n",
    "    plt.savefig(path+str(i)+'.png')    \n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def validate(plot=False, path='', it=-1):\n",
    "    verr=torch.zeros(num_val)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_val):\n",
    "            val_x, val_y = get_validation_demonstration(i)\n",
    "\n",
    "            cond_step = 0\n",
    "            observation = torch.Tensor([val_y[cond_step, :], val_x[cond_step, :]]).view(1, dx+dy).float().cuda()\n",
    "            \n",
    "            pred_traj0, pred_traj1 = torch.zeros_like(val_y), torch.zeros_like(val_y)\n",
    "            pred_traj0[cond_step, :] = val_y[cond_step, :]\n",
    "            pred_traj1[cond_step, :] = val_y[cond_step, :]\n",
    "\n",
    "            for t in range(1, t_steps):\n",
    "                pred0, pred1 = model(observation, torch.unsqueeze(val_x[t], 0))\n",
    "                pred_traj0[t, :], _ = pred0.chunk(2, dim = -1)  # pred[0]: mean, pred[1]: std\n",
    "                pred_traj1[t, :], _ = pred1.chunk(2, dim = -1)\n",
    "            \n",
    "            verr0, verr1 = torch.sum((val_y - pred_traj0) ** 2), torch.sum((val_y - pred_traj1) ** 2)\n",
    "#             print(f'v0: {verr0}\\nv1: {verr1}')\n",
    "            if verr0 < verr1:\n",
    "                verr[i] = verr0\n",
    "                if plot:\n",
    "                    plot_trajs(path, i, val_x.cpu(), val_y.cpu(), pred_traj0.cpu(), 'r')\n",
    "            else:\n",
    "                verr[i] = verr1\n",
    "                if plot:\n",
    "                    plot_trajs(path, i, val_x.cpu(), val_y.cpu(), pred_traj1.cpu(), 'b')\n",
    "            \n",
    "    return torch.mean(verr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = f'val/{int(time.time())}'\n",
    "\n",
    "model = BCNP((1, 1))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=3e-4, params=model.parameters(), betas=(0.9, 0.999), amsgrad=True)\n",
    "\n",
    "val_after_iter = 2500\n",
    "plot_after_iter = 25000\n",
    "iters = 10000000\n",
    "\n",
    "losses = []\n",
    "min_verr = 1e6\n",
    "epsilon = 0.1\n",
    "\n",
    "for i in range(iters):\n",
    "    obss, tx, ty = sample_training_demonstration()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    ty_preds = model(obss, tx)\n",
    "    loss0, loss1 = log_prob_loss(ty, ty_preds[0]), log_prob_loss(ty, ty_preds[1])\n",
    "    \n",
    "    if torch.rand(1) < epsilon and i < 50000:\n",
    "        if torch.rand(1) < 0.5:\n",
    "            model.f0.requires_grad = True\n",
    "            model.f1.requires_grad = False\n",
    "            loss0.backward()\n",
    "        else:\n",
    "            model.f0.requires_grad = False\n",
    "            model.f1.requires_grad = True\n",
    "            loss1.backward()\n",
    "    else:\n",
    "        if loss0 < loss1:\n",
    "            model.f0.requires_grad = True\n",
    "            model.f1.requires_grad = False\n",
    "            loss0.backward()\n",
    "        else:\n",
    "            model.f0.requires_grad = False\n",
    "            model.f1.requires_grad = True\n",
    "            loss1.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "#     if i%500 == 0:\n",
    "#         print(f'{i}: {loss}')\n",
    "    \n",
    "    if i%val_after_iter == 0:\n",
    "        if i%plot_after_iter == 0:\n",
    "            d_path = f'{root_path}/{str(i)}/'\n",
    "            try:\n",
    "                os.makedirs(d_path)\n",
    "            except:\n",
    "                pass\n",
    "            verr = validate(True, d_path, i)\n",
    "        else:\n",
    "            verr = validate()\n",
    "        print(f\"{i}: {verr}\")\n",
    "        losses.append(verr)\n",
    "\n",
    "        if verr < min_verr:\n",
    "            min_verr = verr\n",
    "            print(f\"Best validation\")\n",
    "            torch.save(model.state_dict(), f'{path}/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4371c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
