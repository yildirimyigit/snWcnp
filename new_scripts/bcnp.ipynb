{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7ad5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd343511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device.type)\n",
    "\n",
    "# ---\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "514d5f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 200, 1]) torch.Size([100, 200, 1])\n"
     ]
    }
   ],
   "source": [
    "t_steps = 200\n",
    "num_demos = 100\n",
    "dx, dy = 1, 1\n",
    "x = torch.linspace(0, 1, t_steps).repeat(int(num_demos/2), 1)\n",
    "\n",
    "noise = torch.clamp(torch.randn(x.shape)*1e-4**0.5, min=0)\n",
    "y0 = torch.unsqueeze(torch.sin(x*torch.pi) + noise, 2)\n",
    "\n",
    "y1 = 1-y0\n",
    "\n",
    "x = torch.unsqueeze(x.repeat(2,1), 2)\n",
    "y = torch.cat((y0, y1), 0)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "28a2865b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x[:50, :, 0], y[:50, :, 0], 'b', alpha=0.3)\n",
    "plt.plot(x[51:, :, 0], y[51:, :, 0], 'r', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b11b723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = 6\n",
    "\n",
    "def sample_training_demonstration():    \n",
    "    rand_traj_ind = np.random.randint(0, num_demos)\n",
    "    n = np.random.randint(1, n_max+1)\n",
    "\n",
    "    rand_traj = y[rand_traj_ind, :, :]\n",
    "\n",
    "    observation_indices = np.random.choice(np.arange(t_steps), n+1, replace=False) # n+1: +1 is for sampling the target\n",
    "    \n",
    "    observations = torch.cat((rand_traj[observation_indices[:-1], :], \n",
    "                              x[rand_traj_ind, observation_indices[:-1], :]), 1)\n",
    "    targetX = torch.Tensor(x[rand_traj_ind, observation_indices[-1], :])\n",
    "    targetY = torch.Tensor(rand_traj[observation_indices[-1], :])\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        return observations.float().cuda(), targetX.float().cuda(), targetY.float().cuda()\n",
    "    else:\n",
    "        return observations.float(), targetX.float(), targetY.float()\n",
    "    \n",
    "    \n",
    "aadsada = sample_training_demonstration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "334b714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCNP(nn.Module):\n",
    "    def __init__(self, in_shape):\n",
    "        super(BCNP, self).__init__()\n",
    "        \n",
    "        dx, dy = in_shape[0], in_shape[1]\n",
    "        \n",
    "        dz = 128\n",
    "        dzt = dz+dx\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(dx+dy, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dz)\n",
    "        )\n",
    "        \n",
    "        self.f0 = nn.Sequential(\n",
    "            nn.Linear(dzt, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dy*2)\n",
    "        )\n",
    "\n",
    "        self.f1 = nn.Sequential(\n",
    "            nn.Linear(dzt, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, dy*2)\n",
    "        )\n",
    "\n",
    "#         self.f2 = nn.Sequential(\n",
    "#             nn.Linear(dzt, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, dy*2)\n",
    "#         )\n",
    "        \n",
    "#         self.lin0 = nn.Linear(dz+dy*2, dy)\n",
    "#         self.lin1 = nn.Linear(dz+dy*2, dy)\n",
    "#         self.lin2 = nn.Linear(dz+dy*2, dy)\n",
    "\n",
    "    def forward(self, observations, target):\n",
    "        z_out = self.encoder(observations)\n",
    "        z = torch.mean(z_out, dim=0)\n",
    "        \n",
    "        zs = z.repeat(target.shape[0], 1).to(device)  # repeating the same z for each target\n",
    "        print(\"tes\")\n",
    "        print(z.shape)\n",
    "        print(zs.shape)\n",
    "        z_target = torch.cat((zs, target), 1)\n",
    "        \n",
    "        print(z_target.shape)\n",
    "        \n",
    "        m0, sig0 = self.f0(z_target)\n",
    "        m1, sig1 = self.f1(z_target)\n",
    "        m2, sig2 = self.f2(z_target)\n",
    "        \n",
    "#         fzs = z.repeat(3, 1).to(device)  # 3 decoders (f)\n",
    "        \n",
    "        out0 = self.lin0(torch.cat((z, m0, sig0), 1))\n",
    "        out1 = self.lin1(torch.cat((z, m1, sig1), 1))\n",
    "        out2 = self.lin2(torch.cat((z, m2, sig2), 1))\n",
    "        \n",
    "        return out0, out1, out2\n",
    "        \n",
    "#         sig0, sig1, sig2 = F.softplus(sig0), F.softplus(sig1), F.softplus(sig2)\n",
    "#         dist0 = D.Independent(D.Normal(loc=m0, scale=sig0), 1)\n",
    "#         dist1 = D.Independent(D.Normal(loc=m1, scale=sig1), 1)\n",
    "#         dist2 = D.Independent(D.Normal(loc=m2, scale=sig2), 1)\n",
    "        \n",
    "#         p0, p1, p2 = torch.mean(dist0.log_prob(target)), torch.mean(dist1.log_prob(target)), torch.mean(dist2.log_prob(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f19026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m obss, tx, ty \u001b[38;5;241m=\u001b[39m sample_training_demonstration()\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m ty_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss0 \u001b[38;5;241m=\u001b[39m mse(ty, ty_pred[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m     19\u001b[0m loss1 \u001b[38;5;241m=\u001b[39m mse(ty, ty_pred[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mBCNP.forward\u001b[0;34m(self, observations, target)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(z\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(zs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 53\u001b[0m z_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(z_target\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     57\u001b[0m m0, sig0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf0(z_target)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 1"
     ]
    }
   ],
   "source": [
    "model = BCNP((1, 1))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters(), betas=(0.9, 0.999), amsgrad=True)\n",
    "\n",
    "val_after_epoch = 2500\n",
    "epoch = 1\n",
    "\n",
    "losses = np.zeros(int(epoch/val_after_epoch))\n",
    "min_loss = 1e6\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "for i in range(epoch):\n",
    "    obss, tx, ty = sample_training_demonstration()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    ty_preds = model(obss, tx)\n",
    "    loss0 = mse(ty, ty_pred[0].detach())\n",
    "    loss1 = mse(ty, ty_pred[1].detach())\n",
    "    loss2 = mse(ty, ty_pred[2].detach())\n",
    "    \n",
    "    print(loss0, loss1, loss2)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(i, end=\"\\r\")\n",
    "    if i%val_after_epoch == 0:\n",
    "        val_loss = validate()\n",
    "        print(f\"{i}: {val_loss}\")\n",
    "    \n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'{path}../../best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4371c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
