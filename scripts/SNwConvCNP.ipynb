{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562b7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e34a03",
   "metadata": {},
   "source": [
    "**Torch, Numpy stuff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4dfcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device.type)\n",
    "\n",
    "# ---\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecdd4b0",
   "metadata": {},
   "source": [
    "---\n",
    "**Training Data**\n",
    "\n",
    "Demonstration data contains a list of **d** scenes:\n",
    "\n",
    "- ~~Each scene contains a list of trajectories of **p** people, where p is **not constant**~~\n",
    "- A trajectory is a list of **t** states, where t = 400\n",
    "- A state is a **s** = 4 dimensional variable\n",
    " - State = (d<sub>goal<sub>x</sub></sub>, d<sub>goal<sub>y</sub></sub>, v<sub>x</sub>, v<sub>y</sub>)\n",
    "    \n",
    "> Shape of data is (d, ~~p,~~ t, s) => (d, ~~p,~~ 400, 4)\n",
    "\n",
    "---\n",
    "\n",
    "Train, test, val split: 0.8, 0.01, 0.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58f7e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def data_from_demonstrations(obs_dims=[0,1], tar_dims=[2,3], path=\"../data/input/\"):\n",
    "#     data = np.load(f\"{path}/states_processed.npy\")\n",
    "#     X, Y = data[:,:,:,obs_dims], data[:,:,:,tar_dims]\n",
    "#     return X, Y\n",
    "\n",
    "\n",
    "# # for testing purposes\n",
    "# def synthetic_data(n=10):\n",
    "#     tlen = 400\n",
    "#     X = np.zeros((n, tlen, 1))\n",
    "#     Y = np.zeros((n, tlen, 1))\n",
    "#     for i in range(n):\n",
    "#         X[i] = np.random.uniform(0, 1, tlen).reshape(tlen, 1)\n",
    "#         Y[i] = np.sin(X[i]*2*np.pi)/n + i/n\n",
    "#     return X, Y\n",
    "\n",
    "# #X, Y = data_from_demonstrations()\n",
    "# X, Y = synthetic_data()\n",
    "\n",
    "# X_train, X_rem, Y_train, Y_rem = train_test_split(X, Y, train_size=0.8)\n",
    "\n",
    "# # 0.2 * 0.05 = 0.01 (test size in entire data)\n",
    "# test_sz = 0.05\n",
    "# X_val, X_test, Y_val, Y_test = train_test_split(X_rem, Y_rem, test_size=test_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af99720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_trajectories(X, Y):\n",
    "#     d, t, s = X.shape\n",
    "#     for i in range(d):\n",
    "#         plt.plot(X[i], Y[i], \".\")\n",
    "\n",
    "\n",
    "# plot_trajectories(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9fc4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preparing the data\n",
    "\n",
    "**n <= n<sub>max</sub>** random number of random observations on a random trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50753d69",
   "metadata": {},
   "source": [
    "**get image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dca7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "def get_frames(path, demonstration_id, observation_ids):\n",
    "    frames_path = f'{path}{demonstration_id}/'\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    frames = []\n",
    "    for i in observation_ids:\n",
    "        frames.append(transform(Image.open(f\"{frames_path}{i}.jpg\")))\n",
    "                      \n",
    "    frames = torch.stack(frames, 0)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974c38a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = 20\n",
    "d_size = 10000  # nof demonstrations\n",
    "t_size = 400  # length of trajectories\n",
    "path=\"../data/processed/input/\"\n",
    "\n",
    "def sample_training_demonstration():\n",
    "#     d, t, s = X_train.shape\n",
    "    \n",
    "    rand_traj_ind = np.random.randint(0, d_size)\n",
    "    n = np.random.randint(1, n_max+1)\n",
    "#    rand_traj = X_train[rand_traj_ind]\n",
    "#     rand_out = Y_train[rand_traj_ind]\n",
    "\n",
    "    rand_traj = np.load(f\"{path}{rand_traj_ind}/states.npy\")\n",
    "\n",
    "    observation_indices = np.random.choice(np.arange(t_size), n+1, replace=False) # n+1: +1 is for sampling the target\n",
    "    \n",
    "    frames = get_frames(path, rand_traj_ind, observation_indices[:-1])\n",
    "    \n",
    "    observations = torch.from_numpy(rand_traj[observation_indices[:-1], :])\n",
    "    targetX = torch.unsqueeze(torch.from_numpy(rand_traj[observation_indices[-1], 0:2]), 0)\n",
    "    targetY = torch.unsqueeze(torch.from_numpy(rand_traj[observation_indices[-1], 2:]), 0)\n",
    "    \n",
    "    return frames.float().cuda(), observations.float().cuda(), targetX.float().cuda(), targetY.float().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a659c05",
   "metadata": {},
   "source": [
    "---\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNP, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(8, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(4+64*4*4,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,1024)\n",
    "        )\n",
    "        \n",
    "        self.query = nn.Sequential(\n",
    "            nn.Linear(1024+2,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,2*2)\n",
    "        )\n",
    "\n",
    "    def forward(self, frames, observations, target):\n",
    "        # n < n_max frames of a scene along with momentary observations are concatenated to constitute input\n",
    "        scene_encodings = torch.flatten(self.cnn(frames))\n",
    "        scene_encodings = self.cnn(frames).view(frames.shape[0], 64*4*4)\n",
    "        encoder_in = torch.cat((observations, scene_encodings), 1)\n",
    "        r = self.encoder(encoder_in)\n",
    "        \n",
    "        r_avg = torch.mean(r, dim=0)\n",
    "        r_avgs = r_avg.repeat(target.shape[0], 1)  # repeating the same r_avg for each target\n",
    "        r_avg_target = torch.cat((r_avgs, target), 1)\n",
    "        query_out = self.query(r_avg_target)\n",
    "        \n",
    "        return query_out\n",
    "\n",
    "    \n",
    "def log_prob_loss(output, target):\n",
    "    mean, sigma = output.chunk(2, dim = -1)\n",
    "    sigma = F.softplus(sigma)\n",
    "    dist = D.Independent(D.Normal(loc=mean, scale=sigma), 1)\n",
    "    return -torch.mean(dist.log_prob(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620296c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 8.28280258178711\n",
      "1: 7.037246227264404\n",
      "3: 5.927742004394531\n",
      "5: 5.488465785980225\n",
      "9: 4.784801483154297\n",
      "13: 4.704505920410156\n",
      "14: 4.675440311431885\n",
      "16: 2.7072501182556152\n",
      "17: 2.3558242321014404\n",
      "18: 1.8004528284072876\n",
      "21: 0.7765635251998901\n",
      "39: 0.6775355935096741\n",
      "90: 0.6664631366729736\n",
      "99: -0.217495858669281\n",
      "298: -0.49229395389556885\n",
      "474: -0.5864773988723755\n",
      "1411: -0.6199854612350464\n",
      "1537: -0.6524862051010132\n",
      "1663: -0.6573606729507446\n",
      "2039: -1.1794071197509766\n",
      "10535: -1.1954172849655151\n",
      "46936: -1.2206614017486572\n",
      "89900: -1.3846296072006226\n",
      "91760: -1.4742966890335083\n",
      "214934: -1.6921050548553467\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = CNP()\n",
    "nn.init.uniform_(model.weight)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters(), betas=(0.9, 0.999), amsgrad=True)\n",
    "\n",
    "epoch = 100000000\n",
    "\n",
    "losses = np.zeros(epoch)\n",
    "min_loss = 1e6\n",
    "\n",
    "for i in range(epoch):\n",
    "    fs, obss, tx, ty = sample_training_demonstration()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    ty_pred = model(fs, obss, tx)\n",
    "    loss = log_prob_loss(ty, ty_pred)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    cur_loss = loss.data\n",
    "    losses[i] = cur_loss\n",
    "    \n",
    "    if cur_loss < min_loss:\n",
    "        min_loss = cur_loss\n",
    "        print(f\"{i}: {cur_loss}\")\n",
    "        torch.save(model.state_dict(), f'{path}../best_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102caa83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
